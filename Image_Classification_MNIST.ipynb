{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries.\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense ,Flatten ,Conv2D ,MaxPooling2D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-1:Load and preprocess the data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the MNIST data\n",
    "\n",
    "mnist_data = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data size between 0 to 1.\n",
    "def scale_mnist_data(train_images, test_images):\n",
    "    return train_images/255,test_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a dummy channel dimension\n",
    "scaled_train_images = scaled_train_images[..., np.newaxis]\n",
    "scaled_test_images = scaled_test_images[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-2:Build the convolutional neural network model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model.\n",
    "def get_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3,3), padding = 'SAME',activation = 'relu', input_shape = input_shape ))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(scaled_train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-3:Compile the model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model.\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer = 'adam',\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-4:Fit the model to the training data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model.\n",
    "def train_model(model, scaled_train_images, train_labels):\n",
    "    history = model.fit(scaled_train_images,train_labels,epochs = 5)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "history = train_model(model, scaled_train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-5:Plot the learning curves"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy vs Epochs plot\n",
    "acc_plot = frame.plot(y=\"accuracy\", title=\"Accuracy vs Epochs\", legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss vs Epochs plot\n",
    "acc_plot = frame.plot(y=\"loss\", title = \"Loss vs Epochs\",legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-6:Evaluate the model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model.\n",
    "def evaluate_model(model, scaled_test_images, test_labels):\n",
    "    return model.evaluate(scaled_test_images, test_labels,verbose=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, scaled_test_images, test_labels)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-7:Model predictions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model prediction\n",
    "num_test_images = scaled_test_images.shape[0]\n",
    "\n",
    "random_inx = np.random.choice(num_test_images, 4)\n",
    "random_test_images = scaled_test_images[random_inx, ...]\n",
    "random_test_labels = test_labels[random_inx, ...]\n",
    "\n",
    "predictions = model.predict(random_test_images)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
    "\n",
    "for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
    "    axes[i, 0].imshow(np.squeeze(image))\n",
    "    axes[i, 0].get_xaxis().set_visible(False)\n",
    "    axes[i, 0].get_yaxis().set_visible(False)\n",
    "    axes[i, 0].text(10., -1.5, f'Digit {label}')\n",
    "    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n",
    "    axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
    "    axes[i, 1].set_title(f\"Categorical distribution. Model prediction: {np.argmax(prediction)}\")\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "tensor-flow-2-1",
   "graded_item_id": "g0YqY",
   "launcher_item_id": "N6gmY"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}